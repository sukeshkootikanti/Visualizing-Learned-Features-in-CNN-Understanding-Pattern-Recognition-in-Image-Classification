# Visualizing-Learned-Features-in-CNN-Understanding-Pattern-Recognition-in-Image-Classification
Visualizing Learned Features in Convolutional Neural Networks: Understanding Pattern Recognition in Image Classification

The CNNs have been one of the most accurate models for image classification but the black box makes decision making hard to explain. This paper focuses on the ability to understand the internal workings of Convolutional Neural Networks (CNNs) by visualizing the features learned by the networks during the course of the image classification tasks. We work on CIFAR-10 database which is a well-known database with total of 60,000 color images that are equally divided into 10 classes. Based on Grad-CAM (Gradient-weighted Class Activation Mapping) and saliency maps, we hope to identify which parts of the input images the CNN attends to during its decision making. The specific architecture used in the present work is VGG16, selecting transfer learning as the approach to improve the performance of the model for CIFAR-10 data set. According to our results, test sample has an accuracy of 59.75% and the use of visualization it become clear that the CNN learns to pay attention to the body shape and facial features in a frog category. This research emphasizes the need to have model interpretability especially in deep learning Confirming that the proposed VGG16 CNN model was able to obtain a test accuracy on CIFAR-10 set of 59.75% and thus be able to learn key features for image classification. But demerits are; simple model, skewed datasets, and high image resolution. Future work could build on these ideas with future more complex architectures ranging from ResNet and DenseNet as well as apply more complex form of data augmentation and hyperparameter optimization for improving the results of our model and also improving the interpretability of the model.
